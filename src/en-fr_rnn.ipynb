{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ggb8j0WPXfc"
      },
      "outputs": [],
      "source": [
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nNxffFzQLqzk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import unicodedata\n",
        "import re\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import time\n",
        "import random\n",
        "import evaluate\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hkSDHyhWV0tx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOWgliCdMjRD"
      },
      "source": [
        "## Download and extract the dataset\n",
        "\n",
        "- the text file containing the translation pairs should end up at the path `data/eng-fra.txt`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5tSgNuKSL-KY"
      },
      "outputs": [],
      "source": [
        "DATASET_URL = \"https://download.pytorch.org/tutorial/data.zip\"\n",
        "r = requests.get(DATASET_URL, stream=True)\n",
        "data_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "data_zip.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcjSM2CYM42k"
      },
      "source": [
        "## Process the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Znhwtp9NfqL"
      },
      "source": [
        "### Get the pairs of translations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kF3GeB9EMuS3"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"data/eng-fra.txt\"\n",
        "pairs = []\n",
        "DATASET_USAGE = 1\n",
        "\n",
        "\n",
        "def read_pairs():\n",
        "    with open(DATASET_PATH, \"r\", encoding=\"utf8\") as f:\n",
        "        pairs = f.read().strip().split(\"\\n\")\n",
        "        random.shuffle(pairs)\n",
        "        pairs = pairs[: int(DATASET_USAGE * len(pairs))]\n",
        "        return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zahX5WKbbIGB",
        "outputId": "a57f920b-ad45-4be9-c5db-ffe06a00d1c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "135842"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(read_pairs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXC9kgvMOIoy",
        "outputId": "441d0de7-4c7d-4e92-aecc-3fb38e4a7eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['You seem happy.\\tTu sembles heureux.',\n",
              " \"The pain hasn't gone away.\\tLa douleur n'est pas partie.\",\n",
              " \"This is a farce.\\tIl s'agit d'une farce.\",\n",
              " 'I asked them to fix my car.\\tJe leur ai demandé de réparer ma voiture.',\n",
              " \"Don't you remember my name?\\tNe te rappelles-tu pas mon nom ?\"]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_pairs()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDjtoGHtsbNT",
        "outputId": "34931231-ef64-4a36-a64a-6a77b4ab59c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This boat is seaworthy.\\tLe navire est en état de naviguer.',\n",
              " \"You're alone, aren't you?\\tVous êtes seule, n'est-ce pas ?\",\n",
              " \"Yes, I'm a student too.\\tOui, je suis aussi étudiant.\",\n",
              " \"I remember mentioning it once or twice.\\tJe me rappelle l'avoir mentionné à une ou deux reprises.\",\n",
              " 'I know what those books are like.\\tJe sais à quoi ces ouvrages ressemblent.']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_pairs()[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA5zS6l8NiZ2"
      },
      "source": [
        "### Split the pairs and normalize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gTdQsitmNGs8"
      },
      "outputs": [],
      "source": [
        "PAIR_DELIMETER = \"\\t\"\n",
        "MAX_LEN = 10\n",
        "\n",
        "\n",
        "# Remove any accented characters and non-ASCII symbols\n",
        "# From: https://stackoverflow.com/a/7782177\n",
        "def normalize_text(text):\n",
        "    return str(\n",
        "        unicodedata.normalize(\"NFKD\", text.strip().lower())\n",
        "        .encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "    )\n",
        "\n",
        "\n",
        "def remove_special_chars(text):\n",
        "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z!?]+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = normalize_text(text)\n",
        "    return remove_special_chars(text)\n",
        "\n",
        "\n",
        "def read_normalized_pairs():\n",
        "    pairs = read_pairs()\n",
        "    for index, pair in enumerate(pairs):\n",
        "        eng, fra = pair.split(PAIR_DELIMETER)\n",
        "        eng = preprocess_text(eng)\n",
        "        fra = preprocess_text(fra)\n",
        "        pairs[index] = [eng, fra]\n",
        "    filtered = [\n",
        "        pair\n",
        "        for pair in pairs\n",
        "        if len(pair[0].split(\" \")) <= MAX_LEN and len(pair[1].split(\" \")) <= MAX_LEN\n",
        "    ]\n",
        "    return filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RSqfj3Hawtf",
        "outputId": "8d5c0314-0ac3-4d23-927b-0e6a446a07ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "115596"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(read_normalized_pairs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DOQ1uXJtPzi",
        "outputId": "993b6c2d-1a11-48f1-9d1a-7170c225ddd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['i saw him sawing a tree', 'je l ai vu en train de scier un arbre'],\n",
              " ['she aimed at the target', 'elle visa la cible'],\n",
              " ['he came at o clock in the afternoon',\n",
              "  'il est venu a trois heures de l apres midi'],\n",
              " ['how does he do it ?', 'comment s y prend il ?'],\n",
              " ['come quickly !', 'depechez vous de venir !']]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_normalized_pairs()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX-4RyO3FFRN",
        "outputId": "1c13a422-7bc0-481e-c579-cbedde5ece2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(eng.split(\" \")) for eng, fra in read_normalized_pairs()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f63iL-IFtivG",
        "outputId": "8d2b3315-c137-4c60-879b-8c1e12baad3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['it s gradually getting colder', 'il fait de plus en plus froid'],\n",
              " ['i want you to get your own place',\n",
              "  'je veux que vous preniez votre propre logement'],\n",
              " ['you have the right to know', 'tu as le droit de savoir'],\n",
              " ['they re part of us', 'ils font partie de nous'],\n",
              " ['how long is the flight ?', 'combien de temps dure le vol ?']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_normalized_pairs()[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KYmwjiYbtmB8"
      },
      "outputs": [],
      "source": [
        "UNK_TOKEN = \"<unk>\"\n",
        "SOS_TOKEN = \"<sos>\"\n",
        "EOS_TOKEN = \"<eos>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split(\" \")\n",
        "\n",
        "\n",
        "def eng_iter(pairs):\n",
        "    for eng, fra in pairs:\n",
        "        yield tokenize(eng)\n",
        "\n",
        "\n",
        "def fra_iter(pairs):\n",
        "    for eng, fra in pairs:\n",
        "        yield tokenize(fra)\n",
        "\n",
        "\n",
        "def build_vocab(pairs=None):\n",
        "    if pairs is None:\n",
        "        pairs = read_normalized_pairs()\n",
        "    specials = [UNK_TOKEN, SOS_TOKEN, EOS_TOKEN, PAD_TOKEN]\n",
        "    eng_vocab = build_vocab_from_iterator(\n",
        "        eng_iter(pairs), specials=specials, special_first=True\n",
        "    )\n",
        "    fra_vocab = build_vocab_from_iterator(\n",
        "        fra_iter(pairs), specials=specials, special_first=True\n",
        "    )\n",
        "    eng_vocab.set_default_index(eng_vocab[UNK_TOKEN])\n",
        "    fra_vocab.set_default_index(fra_vocab[UNK_TOKEN])\n",
        "    return eng_vocab, fra_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FzpOFzjpwDhh"
      },
      "outputs": [],
      "source": [
        "eng_vocab, fra_vocab = build_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oobDiw9_wJgd",
        "outputId": "328c43f8-46e8-41f9-d8bb-f916e1536b0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[12, 690, 79, 805]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_vocab(tokenize(\"he ate an apple\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7dvb8_SwYP1",
        "outputId": "bbd91241-72cc-4ef8-9cc4-0bb1ee93912e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4, 69, 9, 74, 132]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_vocab(tokenize(\"I had a good day\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhefXG4pwn6e",
        "outputId": "87ac160e-073f-4a45-90fd-90524bc5f4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English vocab length: 11300\n"
          ]
        }
      ],
      "source": [
        "print(\"English vocab length:\", len(eng_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUGap_HFwyBN",
        "outputId": "71acbc45-64c1-40b2-a7eb-3223732b5ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French vocab length: 19001\n"
          ]
        }
      ],
      "source": [
        "print(\"French vocab length:\", len(fra_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_6qzAayxee8"
      },
      "source": [
        "## Create the dataloader\n",
        "\n",
        "The data gets loaded with 0s as a default, which is the UNK token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eMBmyM7wKDuo"
      },
      "outputs": [],
      "source": [
        "def max_seq_length(pairs):\n",
        "    eng_max = max([len(eng.split(\" \")) for eng, fra in pairs])\n",
        "    fra_max = max([len(fra.split(\" \")) for eng, fra in pairs])\n",
        "    return max(eng_max, fra_max)\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = max_seq_length(read_normalized_pairs()) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "m5acuwUoxhAH"
      },
      "outputs": [],
      "source": [
        "def text_pipeline(text, vocab):\n",
        "    return vocab(tokenize(text))\n",
        "\n",
        "\n",
        "def prepare_input(text, vocab):\n",
        "    text = text_pipeline(text, vocab)\n",
        "    text += vocab([EOS_TOKEN])\n",
        "    return text\n",
        "\n",
        "\n",
        "def create_dataloader(batch_size):\n",
        "    pairs = read_normalized_pairs()\n",
        "    eng_vocab, fra_vocab = build_vocab(pairs)\n",
        "    # Use MAX_SEQUENCE_LENGTH+1 to allow for the EOS_TOKEN to be added\n",
        "    eng_data = torch.zeros(\n",
        "        len(pairs), MAX_SEQUENCE_LENGTH, dtype=torch.long, device=device\n",
        "    ).fill_(eng_vocab[PAD_TOKEN])\n",
        "    fra_data = torch.zeros(\n",
        "        len(pairs), MAX_SEQUENCE_LENGTH, dtype=torch.long, device=device\n",
        "    ).fill_(eng_vocab[PAD_TOKEN])\n",
        "\n",
        "    for index, (eng, fra) in enumerate(pairs):\n",
        "        eng_datum = prepare_input(eng, eng_vocab)\n",
        "        fra_datum = prepare_input(fra, fra_vocab)\n",
        "\n",
        "        # Add the datum to the dataset\n",
        "        eng_data[index, : len(eng_datum)] = torch.tensor(\n",
        "            eng_datum, dtype=torch.long, device=device\n",
        "        )\n",
        "        fra_data[index, : len(fra_datum)] = torch.tensor(\n",
        "            fra_datum, dtype=torch.long, device=device\n",
        "        )\n",
        "\n",
        "    combined_dataset = TensorDataset(eng_data, fra_data)\n",
        "    return eng_vocab, fra_vocab, DataLoader(combined_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0IlGQY9JtWv",
        "outputId": "8238138f-db2f-4315-e954-7818df1512bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_SEQUENCE_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCuJ17NTXs_y",
        "outputId": "d18f5b9b-06ae-49a3-f4f4-8189761787c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Vocab(), Vocab(), <torch.utils.data.dataloader.DataLoader at 0x7ca4dae2c730>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dl = create_dataloader(64)\n",
        "dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBsZSjSjKqEu",
        "outputId": "20237b0e-aaf9-4e61-91cc-34a4b053fa04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1475,    9, 1256,  864,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [ 170,   11,    9,  867,   17,   66,    2,    3,    3,    3,    3],\n",
            "        [   4, 1535,   10, 1830,    6,  104,    5,    2,    3,    3,    3],\n",
            "        [   4,  956,    7, 3496,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [  13,   14,   51, 2493,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   4,  126,    6,    7, 1670,  158,    2,    3,    3,    3,    3],\n",
            "        [  27, 5273, 3863,    2,    3,    3,    3,    3,    3,    3,    3],\n",
            "        [  70,   22,   10,    5,  821,   96,    8,    2,    3,    3,    3],\n",
            "        [  88,   92,    9,  676,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [  12,   26, 1044,  338, 1524,    2,    3,    3,    3,    3,    3],\n",
            "        [  53,   26,    9,  920,   17, 1320, 4275,    2,    3,    3,    3],\n",
            "        [   4,   99,   36,  925,   58,   15,    2,    3,    3,    3,    3],\n",
            "        [  12,   26,  101,  249, 1078,  580,    2,    3,    3,    3,    3],\n",
            "        [  16,   26, 1987,   86,    9, 8407,    2,    3,    3,    3,    3],\n",
            "        [   4,  114,    5,   77,   35,  754,   24,   19,    2,    3,    3],\n",
            "        [  27,   34,  415,   72,  451,   72,   54,  280,    2,    3,    3],\n",
            "        [   4,   32, 1643, 1222,   17,   15, 1211,    2,    3,    3,    3],\n",
            "        [   4,   26,  210,   33,  170,  158,    2,    3,    3,    3,    3],\n",
            "        [  16,  227,  469,  210,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   7,  528, 4128,    7, 4515, 6109,    2,    3,    3,    3,    3],\n",
            "        [  90,   18,   23,  778,  124,    6,    8,    2,    3,    3,    3],\n",
            "        [  13,   26, 2205,  108,    4, 1276,   60,    2,    3,    3,    3],\n",
            "        [   4,  125, 1675,    2,    3,    3,    3,    3,    3,    3,    3],\n",
            "        [   7,  757, 2264, 1277,    7, 1858,    2,    3,    3,    3,    3],\n",
            "        [   7,  871,   28, 1560,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [4776, 2150,   55,   92,    7, 4737,   17,    7,  844,    2,    3],\n",
            "        [  13,   14,    7, 1386,   36,    7, 2849,    2,    3,    3,    3],\n",
            "        [   4,   93,  120,  266,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [  20,  830,   26,  795,   86,    9,  706,  870, 1759,    2,    3],\n",
            "        [  16,   65,    9,  134,   17, 2439,    2,    3,    3,    3,    3],\n",
            "        [   5,   69,   19, 2445,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [  18,    5,  109,   52,    8,    2,    3,    3,    3,    3,    3],\n",
            "        [   7, 5744, 2858,    9, 1649, 6337,    2,    3,    3,    3,    3],\n",
            "        [   5,   31, 2832,    2,    3,    3,    3,    3,    3,    3,    3],\n",
            "        [  22,   10,  202,   24,   20,  156,    2,    3,    3,    3,    3],\n",
            "        [  16,  191,    6,  110,    9,  381,    2,    3,    3,    3,    3],\n",
            "        [  23,   31,  289,  404,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   4,   32,   36,   29,  783,  311,    2,    3,    3,    3,    3],\n",
            "        [   7, 2516,   61, 1193,   43, 6836,    2,    3,    3,    3,    3],\n",
            "        [  27,   11,  367,  226,   20, 3783,    2,    3,    3,    3,    3],\n",
            "        [   4,   32,   95,  233,    6,  397,   94,    5,  397,    8,    2],\n",
            "        [  16,   11,  491,    6,  121,  106,    2,    3,    3,    3,    3],\n",
            "        [ 167, 9685,    7,  712,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   4,  191,    6,  246,    5,  147,    2,    3,    3,    3,    3],\n",
            "        [  18,    5,   56,   13,   14,   73,    6,  583,    8,    2,    3],\n",
            "        [  28,    5, 1124,  285,    8,    2,    3,    3,    3,    3,    3],\n",
            "        [ 108,   55,    5,  194,    8,    2,    3,    3,    3,    3,    3],\n",
            "        [  76,   14,  185,   71,  199,    9, 2342,    2,    3,    3,    3],\n",
            "        [   9,  678,  629,  227,  174,   19,    2,    3,    3,    3,    3],\n",
            "        [  13,   14,  264,    6,   35, 2804,    2,    3,    3,    3,    3],\n",
            "        [   5,   31,   51,  264,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [  20,  559, 2852,    5,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   4,   55,   21,    6,   89,  143,    2,    3,    3,    3,    3],\n",
            "        [  11,   15,   41,    5,   37,    6,  121,    8,    2,    3,    3],\n",
            "        [  20, 1789,   11,    9, 1557, 1502,    2,    3,    3,    3,    3],\n",
            "        [   4,   32,   36,   74,   49, 7150,    2,    3,    3,    3,    3],\n",
            "        [   4,   34, 1584,   47,    5,  319,    2,    3,    3,    3,    3],\n",
            "        [  16,  234,    7, 1163,  141,   44, 1942,    2,    3,    3,    3],\n",
            "        [  35, 1215,    6,  209,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   4,   69,    6, 4315,   44,  670,    2,    3,    3,    3,    3],\n",
            "        [  27,  119,  272,   17,   54,  783,    2,    3,    3,    3,    3],\n",
            "        [  81,   14,    7,  743,    8,    2,    3,    3,    3,    3,    3],\n",
            "        [ 110,  150,    6,  113,   60,   41,   29, 3414,    2,    3,    3],\n",
            "        [   4,   32,   36,  150,    4,   37,    7,  160,    2,    3,    3]],\n",
            "       device='cuda:0') tensor([[ 4749,    26,  1537,  1228,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   18,   196,     9,    26,  1431,     6,    80,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,    19,   170,    10,  1240,     6,     8,    14,  1681,     2,\n",
            "             3],\n",
            "        [   17,    21,  1808,    12,  4511,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   33,     9,   235,   837,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [    4,    31,   747,    59,  1867,   137,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   29,  3030,  6442,     2,     3,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   77,    13,     8,  4113,     8,    10,     5,    23,     7,     2,\n",
            "             3],\n",
            "        [ 2135,     8,    48,    11,     8,   165,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   11,   716,   359,     6,   676,    60,    85,    72,  1786,     2,\n",
            "             3],\n",
            "        [   11,    44,   155,    26,   994,     6,  3982,  2957,     2,     3,\n",
            "             3],\n",
            "        [    4,    19,    25,    31,    10,    65,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   11,    61,    45,    73,   469,  2068,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   24,     5,    72,  2735,    98,    20, 13141,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,   142,     8,  2805,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   29,   106,   374,   148,   382,    15,    63,   266,     2,     3,\n",
            "             3],\n",
            "        [    4,    31,  1071,  1926,     6,    22,    54,     2,     3,     3,\n",
            "             3],\n",
            "        [   17,   122,    25,   278,    34,    18,   196,   137,     2,     3,\n",
            "             3],\n",
            "        [   24,     9,   145,   718,   473,    25,   278,     2,     3,     3,\n",
            "             3],\n",
            "        [   28,  4952,    85,  2443,  5995,    28, 10706,     2,     3,     3,\n",
            "             3],\n",
            "        [    5,    60,   334,    23,     6,    18,   131,     7,     2,     3,\n",
            "             3],\n",
            "        [   11,  6129,   134,     4,    32,    31,  1954,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,    32,   189,  4254,   194,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   18,   638, 11949,    59,   463,    41,  2054,     2,     3,     3,\n",
            "             3],\n",
            "        [   28,   871,    85,  1649,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   28,  2456,  6643, 17458,    14,    45,   235,     6,    12,   820,\n",
            "             2],\n",
            "        [   33,     9,    12,  1195,   275,    18,  2978,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,    31,   876,    14,   450,     5,    12,   114,     2,     3,\n",
            "             3],\n",
            "        [   22,   853,     5,    72,   427,    98,    20,  1030,  2031,  2080,\n",
            "             2],\n",
            "        [   24,     5,   101,    27,  2590,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   16,    37,    57,   177,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   16,  1960,    70,     7,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   28,  3439,  6874,    26,  3989,  4099,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   16,    62,  4278,     2,     3,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   13,  1022,    10,    46,    69,   247,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   24,   420,   720,    28,   259,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   23,    25,  5100,     2,     3,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [    4,    13,    31,    45,    66,   952,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   28,  3372,   270,  5190,     6, 10387,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   29,   317,   405,    22,  5579,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [    4,    31,   108,   384,    34,   390,   483,     8,   390,     7,\n",
            "             2],\n",
            "        [   24,   571,     6,   107,   100,    93,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [ 1361,  2311,    14,   661,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [    4,   221,    49,  2757,   113,   887,  9046,     2,     3,     3,\n",
            "             3],\n",
            "        [  369,     8,    36,    11,   112,  2174,     7,     2,     3,     3,\n",
            "             3],\n",
            "        [ 1039,     8,   184,    20,     7,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [  134,  7568,    16,     7,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [ 2035,     6,   336,    20,  2121,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   26,  3232,   783,    37, 14586,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   33,     9,   956,    27,    52,  8086,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [    8,    43,    68,   717,     2,     3,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [   22,   600,     9,     5,   127,   961,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   11,    32,  2038,    28,   159,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [    9,    22,    12,    42,    22,    15,    16,    39,   107,     7,\n",
            "             2],\n",
            "        [   69,  3293,     9,    26,   961,    45,   335,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,    13,    31,    10,   129,    34,  4917,     2,     3,     3,\n",
            "             3],\n",
            "        [   17,  1233,    22,    15,     8,    64,    47,  4531,     2,     3,\n",
            "             3],\n",
            "        [   24,  2534,    12,  2285,     6,    63,  1930,     2,     3,     3,\n",
            "             3],\n",
            "        [  214,  5481,    56,    42,    14,   119,    30,     2,     3,     3,\n",
            "             3],\n",
            "        [   17,    21,    47,  2265,    63,  1312,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   29,    53, 16428,     6,    63,   952,     2,     3,     3,     3,\n",
            "             3],\n",
            "        [   73,     9,    14,   610,     7,     2,     3,     3,     3,     3,\n",
            "             3],\n",
            "        [ 2284,    79,     6, 11560,    92,   174,  4819,     2,     3,     3,\n",
            "             3],\n",
            "        [    4,    13,    31,    10,  1225,     6,   856,    14,   664,     2,\n",
            "             3]], device='cuda:0')\n",
            "torch.Size([64, 11]) torch.Size([64, 11])\n"
          ]
        }
      ],
      "source": [
        "for eng, fra in dl[2]:\n",
        "    print(eng, fra)\n",
        "    print(eng.shape, fra.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiQNebNrL-oM",
        "outputId": "2889960b-267a-4b7a-c59f-8f9b1322679c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1475,    9, 1256,  864,    2,    3,    3,    3,    3,    3,    3],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBFwlDv1MQXe",
        "outputId": "4a40e538-86a9-4020-acd5-7365230f22a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4749,   26, 1537, 1228,    2,    3,    3,    3,    3,    3,    3],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fra[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZYZcqu2Mceu"
      },
      "source": [
        "## Define the model architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "k5SNcm3TMSJ_"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim, bidirectional=False, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_dim)\n",
        "        self.rnn = nn.LSTM(\n",
        "            hidden_dim, hidden_dim, batch_first=True, bidirectional=bidirectional\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        output = self.dropout(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim,\n",
        "        output_size,\n",
        "        bidirectional=False,\n",
        "        dropout=0.0,\n",
        "        fill_val=eng_vocab[SOS_TOKEN],\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.fill_val = fill_val\n",
        "        self.embedding = nn.Embedding(output_size, hidden_dim)\n",
        "        self.rnn = nn.LSTM(\n",
        "            hidden_dim, hidden_dim, batch_first=True, bidirectional=bidirectional\n",
        "        )\n",
        "        fc_in_features = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        self.fc = nn.Linear(fc_in_features, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, encoder_outputs, hidden_state, target_tensor=None):\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        input = torch.zeros(batch_size, 1, dtype=torch.long, device=device).fill_(\n",
        "            self.fill_val\n",
        "        )\n",
        "        outputs = []\n",
        "\n",
        "        for i in range(MAX_SEQUENCE_LENGTH):\n",
        "            output, _ = self.forward_step(input, hidden_state)\n",
        "            # output is of shape: [batch_size, 1, output_size], where output_size is\n",
        "            # num. of unique words in target language\n",
        "            outputs.append(output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # If teacher forcing:\n",
        "                # Use the target tensor's values as the next input, converting them to\n",
        "                # the same shape as the original input\n",
        "                input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                # If not teacher forcing:\n",
        "                # Take the topk of the output and use it as the next input (the topk\n",
        "                # will be of size [batch_size, 1, 1])\n",
        "                _, top_indexes = output.topk(1)\n",
        "                input = top_indexes.squeeze(-1)\n",
        "\n",
        "        # Concatenate all of the outputs along dimension 1, creating the complete\n",
        "        # sequence from individual parts for each input\n",
        "        # (size [batch_size, MAX_SEQUENCE_LENGTH, output_size])\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        outputs = F.log_softmax(outputs, dim=-1)\n",
        "        return outputs\n",
        "\n",
        "    def forward_step(self, input, hidden_state):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden_state = self.rnn(output, hidden_state)\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "m5dzrGHMaJoH"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        output_size,\n",
        "        hidden_dim,\n",
        "        bidirectional=True,\n",
        "        dropout=0.0,\n",
        "        fill_val=eng_vocab[SOS_TOKEN],\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(\n",
        "            input_size, hidden_dim, bidirectional=bidirectional, dropout=dropout\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            hidden_dim,\n",
        "            output_size,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout,\n",
        "            fill_val=fill_val,\n",
        "        )\n",
        "\n",
        "    def forward(self, input, target_tensor=None):\n",
        "        encoder_output, encoder_hidden = self.encoder(input)\n",
        "        decoder_output = self.decoder(encoder_output, encoder_hidden, target_tensor)\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7HJzq25Os0F"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hiTW2MrgOsbQ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, validation_dataloader, model, optimizer, criterion):\n",
        "    # Training\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        input, target = batch\n",
        "        input.to(device)\n",
        "        target.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        output = model(input, target)\n",
        "\n",
        "        loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation loss\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            input, target = batch\n",
        "            input.to(device)\n",
        "            target.to(device)\n",
        "            output = model(input, target)\n",
        "            loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n",
        "            val_loss += loss.item()\n",
        "    model.train()\n",
        "\n",
        "    return total_loss / len(train_dataloader), val_loss / len(validation_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "c1BoNuwaUQ5Y"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    train_dataloader,\n",
        "    validation_dataloader,\n",
        "    model,\n",
        "    epochs,\n",
        "    print_every=20,\n",
        "    checkpoint_path=\".\",\n",
        "    stop_early=True,\n",
        "):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    save_path = f\"{checkpoint_path}/model_checkpoint.pt\"\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    saved_once = False\n",
        "\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    last_epoch_time = start\n",
        "\n",
        "    print(\"Training started...\")\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        train_loss, validation_loss = train_epoch(\n",
        "            train_dataloader, validation_dataloader, model, optimizer, criterion\n",
        "        )\n",
        "\n",
        "\n",
        "        # Save a checkpoint of the encoder and decoder's weights\n",
        "\n",
        "        # Attempt to save the best of the combined losses, without overfitting (too much)\n",
        "\n",
        "        if (\n",
        "            checkpoint_path is not None\n",
        "            and train_loss + validation_loss < best_loss\n",
        "            and train_loss * 1.1 >= validation_loss\n",
        "        ):\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            saved_once = True\n",
        "\n",
        "            best_epoch = epoch\n",
        "\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}\\t | Loss (train): {train_loss:.4f}\\t| Loss (validation): {validation_loss:.4f}\\t| Total Time: {time.time() - start:.4f}s\\t| Epoch Time: {time.time() - last_epoch_time:.4f}s\"\n",
        "            )\n",
        "\n",
        "        last_epoch_time = time.time()\n",
        "\n",
        "\n",
        "        # Stop early if the model is overfitting too much\n",
        "\n",
        "        if stop_early and train_loss * 1.2 < validation_loss and epoch >= 4:\n",
        "            print(\"Stopping early...\")\n",
        "\n",
        "            break\n",
        "\n",
        "\n",
        "    if saved_once:\n",
        "        # Load the best version of the encoder and decoder's weights\n",
        "\n",
        "        print(f\"Loading best checkpoint from epoch {best_epoch}....\")\n",
        "        model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "\n",
        "    print(f\"Took {time.time() - start}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Eb9F9oiGhRY-"
      },
      "outputs": [],
      "source": [
        "def split_dataloader(dataloader, pcts):\n",
        "    b = dataloader.batch_size\n",
        "    datasets = torch.utils.data.random_split(dataloader.dataset, list(pcts))\n",
        "    return tuple(DataLoader(dataset, b) for dataset in datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yWQ1XYCuUQ7p"
      },
      "outputs": [],
      "source": [
        "hidden_size = 512\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vUbOjxypYY4r"
      },
      "outputs": [],
      "source": [
        "eng_vocab, fra_vocab, dataloader = create_dataloader(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9paJR99cZrVW"
      },
      "outputs": [],
      "source": [
        "train_dataloader, validation_dataloader, test_dataloader = split_dataloader(\n",
        "    dataloader, (0.7, 0.2, 0.1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z1VY5tSlCi1",
        "outputId": "1a9b3bd3-2ac9-43e7-cee3-9893936d70d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dataloader size: 80918\n",
            "validation_dataloader size: 23119\n",
            "test_dataloader size: 11559\n"
          ]
        }
      ],
      "source": [
        "print(f\"train_dataloader size:\", len(train_dataloader.dataset))\n",
        "print(f\"validation_dataloader size:\", len(validation_dataloader.dataset))\n",
        "print(f\"test_dataloader size:\", len(test_dataloader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TuyryYXLTAOz"
      },
      "outputs": [],
      "source": [
        "bidirectional = True\n",
        "model = Seq2SeqModel(\n",
        "    len(eng_vocab),\n",
        "    len(fra_vocab),\n",
        "    hidden_size,\n",
        "    bidirectional=bidirectional,\n",
        "    dropout=0.0,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pP630rJCTpIc"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQduqVNOh74u",
        "outputId": "e3cc4fad-a30a-4aad-a984-189b26907fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started...\n",
            "Epoch 1\t | Loss (train): 2.3223\t| Loss (validation): 1.6109\t| Total Time: 76.9069s\t| Epoch Time: 76.9069s\n",
            "Epoch 2\t | Loss (train): 1.1992\t| Loss (validation): 1.3426\t| Total Time: 153.5835s\t| Epoch Time: 76.6765s\n",
            "Epoch 3\t | Loss (train): 0.7852\t| Loss (validation): 1.2690\t| Total Time: 230.4485s\t| Epoch Time: 76.8648s\n",
            "Epoch 4\t | Loss (train): 0.5664\t| Loss (validation): 1.2651\t| Total Time: 307.6803s\t| Epoch Time: 77.2317s\n",
            "Took 307.68041491508484s\n"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    train_dataloader,\n",
        "    validation_dataloader,\n",
        "    model,\n",
        "    EPOCHS,\n",
        "    print_every=1,\n",
        "    checkpoint_path=None,\n",
        "    stop_early=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaefSh3pVfqA"
      },
      "source": [
        "## Test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mo6vlIM1tRBB"
      },
      "outputs": [],
      "source": [
        "def tensor_to_sentence(model_output_indexes, vocab):\n",
        "    sentence = []\n",
        "    for word_index in model_output_indexes:\n",
        "        word = vocab.lookup_token(word_index)\n",
        "        if word == EOS_TOKEN:\n",
        "            break\n",
        "        sentence.append(word)\n",
        "    return \" \".join(sentence)\n",
        "\n",
        "\n",
        "def inference(model, inputs):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        outputs = model(inputs)\n",
        "        model.train()\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def translate(model, input, eng_vocab, fra_vocab):\n",
        "    with torch.no_grad():\n",
        "        input = torch.tensor(\n",
        "            prepare_input(input, eng_vocab), dtype=torch.long, device=device\n",
        "        ).unsqueeze(0)\n",
        "\n",
        "        output = inference(model, input)\n",
        "\n",
        "        output = output.squeeze(0)\n",
        "\n",
        "        _, pred_indexes = output.topk(1, dim=1)\n",
        "        return tensor_to_sentence(pred_indexes, fra_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkE0c3nhoUfM",
        "outputId": "ff6c2de5-8e9c-48a8-a256-100f7bee7e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3336, 2]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prepare_input(\"Wow\", eng_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nMLHZXOTCug",
        "outputId": "25edb371-7d1e-46a6-b767-6aa48baab166"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_vocab[UNK_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IJn4wu2hoWMc",
        "outputId": "88f9d46f-788f-472c-b373-7c5473ee140f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nous avons eu une bonne journee'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(model, \"we had a good day\", eng_vocab, fra_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1SncDtFIS8Mi",
        "outputId": "72dd88e1-b9da-4ae9-e7cf-116f283cf811"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nous sommes alles nager'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(model, \"we went to swim\", eng_vocab, fra_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bZkMopLGS931",
        "outputId": "7c2e5816-b760-424b-f014-c4a06aa6a1da"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nous sommes heureux'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(model, \"we are happy\", eng_vocab, fra_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "joQ9idDPS_eQ",
        "outputId": "48731fe1-6d6d-4e53-8f4d-9abc08dc20f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'j aime ca'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(model, \"I don't like that\", eng_vocab, fra_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbRdrLICfqMH",
        "outputId": "aef9023d-7472-4302-abd8-cb8a2693e026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.29 ms ± 37.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "translate(model, \"we had a good day\", eng_vocab, fra_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5um0gUAiYWZz"
      },
      "source": [
        "### Bleu Scoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bTMX8AsXYyCj"
      },
      "outputs": [],
      "source": [
        "def ref_and_pred(dataloader, model, src_vocab, target_vocab):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    for batch in dataloader:\n",
        "        input, target = batch\n",
        "        output = inference(model, input)\n",
        "        for index, (input_sample, target_sample, output_sample) in enumerate(\n",
        "            zip(input, target, output)\n",
        "        ):\n",
        "            english_input = tensor_to_sentence(input_sample, src_vocab)\n",
        "            _, pred_indexes = output_sample.topk(1, dim=1)\n",
        "            model_translation = tensor_to_sentence(pred_indexes, fra_vocab)\n",
        "            ground_truth = tensor_to_sentence(target_sample, fra_vocab)\n",
        "            references.append(ground_truth)\n",
        "            predictions.append(model_translation)\n",
        "    return references, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "kbYSW3OMYLNx"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "predictions, references = ref_and_pred(test_dataloader, model, eng_vocab, fra_vocab)\n",
        "results = bleu.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7LYyDJUXqO9",
        "outputId": "d05c645a-38fe-4719-c522-b9140affd1b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 0.25979312491709844,\n",
              " 'precisions': [0.5123417299746768,\n",
              "  0.3263852783160814,\n",
              "  0.20590218249764028,\n",
              "  0.13229985659892202],\n",
              " 'brevity_penalty': 1.0,\n",
              " 'length_ratio': 1.0903938381049265,\n",
              " 'translation_length': 75030,\n",
              " 'reference_length': 68810}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "91pK7v4xUFuL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
